{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HCj3HFl9S9QrXLD6oR05kXYmwK_zVQ-Y",
      "authorship_tag": "ABX9TyMphwcPWjk/h5PPUaaz0ufA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzuupp/Object_Detection-Segmentation/blob/main/pytorch-objdet/Pytorch_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection 구현"
      ],
      "metadata": {
        "id": "r-oPzwIvY3TN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZUbtQhw-Yd74"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import functional as FT\n",
        "from torchvision import transforms as T\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split, Dataset\n",
        "import copy\n",
        "import math\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from pycocotools.coco import COCO\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Vg8dVyb2Y0Ix"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "E7LjwOcWay2t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Aqua_data_train_url  = '/content/drive/MyDrive/Aquarium Combined.v2-raw-1024.coco/train'\n",
        "Aqua_data_valid_url = '/content/drive/MyDrive/Aquarium Combined.v2-raw-1024.coco/valid'\n",
        "Aqua_data_test_url = '/content/drive/MyDrive/Aquarium Combined.v2-raw-1024.coco/test'"
      ],
      "metadata": {
        "id": "Bl0T641Jc03m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 변환 함수 생성."
      ],
      "metadata": {
        "id": "AxrQiWIwyBDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train = False):\n",
        "    if train :\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            A.HorizontalFlip(p = 0.3), # 30% 확률로 좌우 뒤집기.\n",
        "            A.VerticalFlip(p = 0.3),   # 30% 확률로 위아래 뒤집기.\n",
        "            A.RandomBrightnessContrast(p = 0.1), # 10% 확률로 밝기/대비 무작위 변화.\n",
        "            A.ColorJitter(p = 0.1), # 10% 확률로 색상/채도/명도 변화\n",
        "            ToTensorV2() # NumPy => PyTorch Tensor 변환\n",
        "        ], bbox_params = A.BboxParams(format = 'coco'))  #객체 탐지는 바운딩박스도 함께 변환해야함.\n",
        "\n",
        "    else:\n",
        "        transform = A.Compose([\n",
        "            A.Resize(600, 600), # our input size can be 600px\n",
        "            ToTensorV2()\n",
        "        ], bbox_params = A.BboxParams(format = 'coco'))\n",
        "\n",
        "    return transform"
      ],
      "metadata": {
        "id": "CARjToGFiiPW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: 학생별 데이터 : [ (\"철수\", 15), (\"영희\", 16), (\"민수\", 14) ]\n",
        "\n",
        "    zip(*batch): 필드별 데이터 : [ (\"철수\", \"영희\", \"민수\"), (15, 16, 14) ]\n",
        "    \"\"\"\n",
        "    return tuple(zip(*batch))"
      ],
      "metadata": {
        "id": "Z1YzXjVSx8v6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터셋 관련 함수"
      ],
      "metadata": {
        "id": "a0H4p94OyKKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# datasets.VisionDataset: 이미지 데이터셋을 만들 때 공통적으로 필요한 기능(루트 경로, transform, target_transform, 데이터 길이, 인덱싱 등)을 기본 제공하는 추상 클래스\n",
        "class AquariumDetection(datasets.VisionDataset):\n",
        "\n",
        "    def __init__(self, root, split = 'train', transform = None, target_transform = None, transforms = None):\n",
        "        # 상속\n",
        "        super().__init__(root, transforms, transform, target_transform)\n",
        "\n",
        "        # 변수 지정\n",
        "        self.split = split\n",
        "        # 경로 지정\n",
        "        self.coco = COCO(os.path.join(root, split, '_annotations.coco.json'))\n",
        "\n",
        "        # 어노테이션 파일의 존재하는키값 가져오기.\n",
        "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
        "\n",
        "        # 어노테이션 파일에 없는건 제외하기 위함인거 같음.\n",
        "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
        "\n",
        "    # id : int\n",
        "    def _load_image(self, id : int):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.coco.imgs = {\n",
        "            1: {\"file_name\": \"0001.jpg\", \"height\": 480, \"width\": 640},\n",
        "            2: {\"file_name\": \"0002.jpg\", \"height\": 720, \"width\": 1280}\n",
        "        }\n",
        "\n",
        "        이런식인데, self.coco.loadImgs(1) 을 해버리면 (id = 숫자),\n",
        "        [{'id': 1, 'file_name': '0001.jpg', 'height': 480, 'width': 640}]\n",
        "        와 같이 해당 형태의 정보를 리스트 형태로 반환함.\n",
        "        그래서 리스트 벗기기 위해서 [0]사용.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        path = self.coco.loadImgs(id)[0]['file_name']\n",
        "        image = cv2.imread(os.path.join(self.rooot, self.split, path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    def _load_target(self, id):\n",
        "\n",
        "        \"\"\"\n",
        "        COCO 어노테이션 JSON은 보통 다음의 구조를 지닌다.\n",
        "        {\n",
        "        \"images\": [\n",
        "            {\"id\": 1, \"file_name\": \"0001.jpg\"},\n",
        "            {\"id\": 2, \"file_name\": \"0002.jpg\"}\n",
        "        ],\n",
        "\n",
        "        \"annotations\": [\n",
        "            {\"id\": 11, \"image_id\": 1, \"category_id\": 3, \"bbox\": [20, 35, 50, 60]},\n",
        "            {\"id\": 12, \"image_id\": 1, \"category_id\": 1, \"bbox\": [200, 250, 60, 80]},\n",
        "            {\"id\": 13, \"image_id\": 2, \"category_id\": 2, \"bbox\": [15, 25, 70, 90]}\n",
        "        ],\n",
        "\n",
        "        \"categories\": [\n",
        "            {\"id\": 1, \"name\": \"fish\"},\n",
        "            {\"id\": 2, \"name\": \"shark\"},\n",
        "            {\"id\": 3, \"name\": \"jellyfish\"}\n",
        "        ]\n",
        "        }\n",
        "\n",
        "\n",
        "        pycocotools.COCO로 위 JSON 읽을 때,\n",
        "        self.coco.anns = {\n",
        "                            11: {\"id\": 11, \"image_id\": 1, \"category_id\": 3, \"bbox\": [20, 35, 50, 60]},\n",
        "                            12: {\"id\": 12, \"image_id\": 1, \"category_id\": 1, \"bbox\": [200, 250, 60, 80]},\n",
        "                            13: {\"id\": 13, \"image_id\": 2, \"category_id\": 2, \"bbox\": [15, 25, 70, 90]},\n",
        "                         }\n",
        "\n",
        "\n",
        "        예를 들어서, 이미지 1의 어노테이션들을 찾고 싶을 때,\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=1) / print(ann_ids)\n",
        "        print(ann_ids) -> [11, 12]\n",
        "        * 이건 단순히 “image_id가 1인 어노테이션들의 id 리스트”예요.\n",
        "        * 즉, 이미지 1에는 annotation 11, 12가 존재한다는 뜻.\n",
        "\n",
        "\n",
        "        이후, self.coco.loadAnns(ann_ids) 호출하면,  -> anns = self.coco.loadAnns([11, 12])\n",
        "\n",
        "        [\n",
        "        {\"id\": 11, \"image_id\": 1, \"category_id\": 3, \"bbox\": [20, 35, 50, 60]},\n",
        "        {\"id\": 12, \"image_id\": 1, \"category_id\": 1, \"bbox\": [200, 250, 60, 80]}\n",
        "        ]\n",
        "\n",
        "        loadAnns()는 전달받은 id 리스트를 이용해서\n",
        "        self.coco.anns 딕셔너리 안에서 해당 id에 해당하는 데이터를 찾아서 리스트 형태로 반환합니다.\n",
        "\n",
        "        \"\"\"\n",
        "        # getAnnIds() → 어떤 annotation들이 있는지 id만 알아냄\n",
        "        # loadAnns() → 그 id들로 실제 내용(박스 좌표, 클래스 등)을 조회\n",
        "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
        "\n",
        "\n",
        "    # 객체를 리스트처럼 인덱싱할 수 있게 : __getitem__\n",
        "    def __getitem__(self,index):\n",
        "\n",
        "        # ids : 어노테이션이 있는것들만 추리게 됨.\n",
        "        id = self.ids[index]\n",
        "\n",
        "\n",
        "        # 내부에서 접근하게 설정한 코드\n",
        "        image = self._load_image(id)\n",
        "        target= self._load_target(id) #이미지에 존재하는 어노테이션의 모든정보 조회 (박스 좌표, 클래스 등)\n",
        "        target = copy.deepcopy(self._load_target(id)) # 통복사 ('진짜'가 변경되지 않도록)\n",
        "\n",
        "        # target = 어노테이션파일, 여기에서 boundingbox, id만 빼서 저장.\n",
        "        boxes = [t['bbox'] + [t['category_id']] for t in target]\n",
        "\n",
        "\n",
        "        # transforms를 적용한 경우와 아닌 경우.\n",
        "        if self.transforms is not None:\n",
        "            # 앞에서 본 이미지 변환.\n",
        "            transformed = self.transforms(image = image, bboxes = boxes)\n",
        "\n",
        "\n",
        "        image = transformed['image']\n",
        "        boxes = transformed['bboxes']\n",
        "\n",
        "        new_boxes = [] # convert from xywh to xyxy\n",
        "        # ❗️ PyTorch / Albumentations / 모델들은 XYXY 형식 (xmin, ymin, xmax, ymax)을 원합니다.\n",
        "        # coco box는 bbox = [x_min, y_min, width, height] 와 같이 정의되어 있음.\n",
        "        '''\n",
        "        그래서 x_min은 항상 그 박스에서 가장 왼쪽에 있는 x좌표\n",
        "        → 즉, x좌표 중 최소값\n",
        "\n",
        "        y_min은 항상 그 박스에서 가장 위쪽에 있는 y좌표\n",
        "        → 즉, y좌표 중 최소값\n",
        "\n",
        "        '''\n",
        "\n",
        "        for box in boxes:\n",
        "            xmin = box[0]\n",
        "            xmax = xmin + box[2]\n",
        "            ymin = box[1]\n",
        "            ymax  = ymin + box[3]\n",
        "\n",
        "            # 왼쪽 위 : xmin,y_min  //  오른쪽 아래 : xmax, ymax\n",
        "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "\n",
        "        boxes = torch.tensor(new_boxes, dtype = torch.float32)\n",
        "\n",
        "        # 변환값을 담을 리스트 생성.\n",
        "        targ = {}\n",
        "        targ['boxes'] = boxes\n",
        "\n",
        "\n",
        "        # PyTorch의 객체 탐지 모델들(Faster R-CNN, SSD, YOLO 등)은 라벨(label) 값을 정수형(LongTensor) 으로 기대\n",
        "        # 즉, float(소수형)이나 bool 타입이면 학습 시 에러가 나요.\n",
        "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype = torch.int64)\n",
        "        targ['image_id'] = torch.tensor([t['image_id'] for i in target])\n",
        "        targ['area'] = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:, 0])\n",
        "        targ['iscrowd'] = torch.tensor\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lWCyaWgKz79S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc = [(1,1),(2,2),(3,3),(4,4)]\n",
        "print(*cc)"
      ],
      "metadata": {
        "id": "FxYWGuR6m2al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551ac9e3-f7f3-48a4-8af4-b251fd35a067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1) (2, 2) (3, 3) (4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fNV1bJ2uUS6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}